<script setup>
import { ref, onMounted, onUnmounted } from 'vue'
import { useChatStore } from '../stores/chat'
import { useWaveform } from '../composables/useWaveform'
import ASRService from '../services/asr'

const chatStore = useChatStore()
const isSupported = ref(false)
const buttonText = ref('æŒ‰ä½è¯´è¯')

// æ³¢å½¢å¯è§†åŒ–
const waveformCanvas = ref(null)
const { init: initWaveform, startVisualization, stopVisualization } = useWaveform()

// æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦æ”¯æŒè¯­éŸ³è¯†åˆ«
onMounted(() => {
  if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
    isSupported.value = true
  } else {
    console.warn('Speech recognition not supported')
  }

  // åˆå§‹åŒ– ASR æœåŠ¡
  ASRService.init({
    appKey: localStorage.getItem('aliyun_appkey') || '',
    onTranscript: (text, isFinal = false) => {
      chatStore.setTranscript(text, isFinal)
    },
    onError: (error) => {
      console.error('ASR Error:', error)
      chatStore.setListening(false)
    }
  })
})

onUnmounted(() => {
  ASRService.stop()
})

// é¼ æ ‡æŒ‰ä¸‹å¼€å§‹å½•éŸ³
async function startRecording() {
  if (!isSupported.value) return
  
  chatStore.setListening(true)
  chatStore.clearTranscript()
  buttonText.value = 'ç›‘å¬ä¸­...'
  
  // åˆå§‹åŒ–æ³¢å½¢å¯è§†åŒ–
  if (waveformCanvas.value) {
    initWaveform(waveformCanvas.value)
  }
  
  // è·å–åª’ä½“æµå¹¶å¯åŠ¨å¯è§†åŒ–
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
    startVisualization(stream)
  } catch (error) {
    console.warn('Could not access microphone for visualization:', error)
  }
  
  // ä½¿ç”¨é˜¿é‡Œäº‘ ASR
  ASRService.start()
}

// é¼ æ ‡æ¾å¼€åœæ­¢å½•éŸ³
function stopRecording() {
  chatStore.setListening(false)
  buttonText.value = 'æŒ‰ä½è¯´è¯'
  
  // åœæ­¢æ³¢å½¢å¯è§†åŒ–
  stopVisualization()
  
  ASRService.stop()
}

// å¤„ç†ç‚¹å‡»ï¼ˆå‘é€å½“å‰è½¬å†™å†…å®¹ï¼‰
function handleClick() {
  if (chatStore.currentTranscript.trim()) {
    // å‘é€æ¶ˆæ¯é€»è¾‘
  }
}
</script>

<template>
  <div class="voice-input">
    <div v-if="chatStore.isListening" class="waveform-container">
      <canvas ref="waveformCanvas" class="waveform-canvas"></canvas>
    </div>
    
    <button
      class="voice-button"
      :class="{ listening: chatStore.isListening }"
      @mousedown="startRecording"
      @mouseup="stopRecording"
      @mouseleave="stopRecording"
      @touchstart.prevent="startRecording"
      @touchend.prevent="stopRecording"
    >
      <span class="icon">{{ chatStore.isListening ? 'ğŸ”´' : 'ğŸ¤' }}</span>
      <span class="text">{{ buttonText }}</span>
    </button>
    
    <div v-if="chatStore.currentTranscript" class="transcript" :class="{ 'is-final': chatStore.isFinalTranscript }">
      <span v-if="!chatStore.isFinalTranscript" class="listening-indicator">â€¢â€¢â€¢</span>
      <span v-else class="final-indicator">âœ“</span>
      {{ chatStore.currentTranscript }}
    </div>
  </div>
</template>

<style scoped>
.voice-input {
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 8px;
}

.waveform-container {
  width: 100%;
  max-width: 300px;
  height: 60px;
  background: rgba(102, 126, 234, 0.1);
  border-radius: 8px;
  overflow: hidden;
  margin-bottom: 8px;
}

.waveform-canvas {
  width: 100%;
  height: 100%;
}

.voice-button {
  display: flex;
  align-items: center;
  gap: 8px;
  padding: 12px 24px;
  border: none;
  border-radius: 24px;
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white;
  font-size: 16px;
  cursor: pointer;
  transition: all 0.3s ease;
  box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
}

.voice-button:hover {
  transform: translateY(-2px);
  box-shadow: 0 6px 20px rgba(102, 126, 234, 0.5);
}

.voice-button.listening {
  background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
  box-shadow: 0 4px 15px rgba(245, 87, 108, 0.4);
  animation: pulse 1.5s infinite;
}

@keyframes pulse {
  0%, 100% {
    box-shadow: 0 4px 15px rgba(245, 87, 108, 0.4);
  }
  50% {
    box-shadow: 0 4px 25px rgba(245, 87, 108, 0.7);
  }
}

.icon {
  font-size: 20px;
}

.transcript {
  max-width: 80%;
  padding: 8px 16px;
  background: rgba(102, 126, 234, 0.1);
  border-radius: 12px;
  font-size: 14px;
  color: #666;
  text-align: center;
  display: flex;
  align-items: center;
  gap: 6px;
  animation: fadeIn 0.3s ease;
}

.transcript.is-final {
  background: rgba(76, 175, 80, 0.1);
  color: #4CAF50;
  border: 1px solid rgba(76, 175, 80, 0.3);
}

.listening-indicator {
  color: #f5576c;
  font-weight: bold;
  animation: blink 1s infinite;
}

.final-indicator {
  color: #4CAF50;
  font-weight: bold;
}

@keyframes blink {
  0%, 100% {
    opacity: 1;
  }
  50% {
    opacity: 0.3;
  }
}

@keyframes fadeIn {
  from {
    opacity: 0;
    transform: translateY(-5px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}
</style>
